\documentclass[aspectratio=169,hyperref={unicode},17pt]{beamer}

\usepackage[T2A]{fontenc}
\usepackage[russian,english]{babel}
\usepackage{listings}
\usepackage{color}
\usepackage{default}
\usepackage{hyperref}
\usepackage{fontspec}

\usefonttheme{professionalfonts}
\usefonttheme{serif}
\setmainfont{Liberation Sans}

% Настройки бимера
\usetheme{Copenhagen}
\usecolortheme{seahorse}
\definecolor{DgisGreen}{RGB}{156, 201, 94}
\setbeamercolor{frametitle}{fg=white,bg=DgisGreen}
\setbeamercolor{title}{fg=white,bg=DgisGreen}
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{footline}[frame number]

% Настройки листинга
\definecolor{comments}{rgb}{0.5,0.5,0.5}
\definecolor{stdtypes}{rgb}{0.3,0.0,0.0}

\lstdefinestyle{cppcode}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=L,
  xleftmargin=\parindent,
  language=C++,
  showstringspaces=false,
  basicstyle=\footnotesize\ttfamily,
  morekeywords={constexpr,static_assert,decltype,co_await,co_return},
  keywordstyle=\bfseries\color{blue},
  commentstyle=\color{comments},
  stringstyle=\color{brown},
  classoffset=1,
  morekeywords=[1]{std,map,launch,future,shared_future,promise,packaged_task,async,move,when_any_result,when_any,tuple,when_all,vector,unique_function},
  keywordstyle=[1]\bfseries\color{stdtypes},
}

\title{Нестандартный future/promise}
\author{Сергей Видюк}
\titlegraphic{\includegraphics[height=1.2cm]{2GISLogo.eps}}
\date{}

\begin{document}

\begin{frame}
 \maketitle
\end{frame}

\begin{frame}[t]{Кратко обо мне}
 \begin{itemize}
  \item Работаю в команде 3D карты мобильной версии 2ГИС
  \item Написал свою реализацию \texttt{future/promise}
 \end{itemize}
\end{frame}

\begin{frame}[fragile,t]{\texttt{std::future} FAQ}

{\em Q:} Когда мы хотим запускать асинхронные задачи?

{\em A:} Кода нам нельзя блокировать текущий поток.

{\em Q:} Что мы можем сделать с \texttt{std::future} на результат асинхронной задачи?

{\em A:} Заблокироваться чтобы получить результат.
\end{frame}

\begin{frame}[fragile,t]{Альтернативы}
\begin{itemize}
  \item portable\_concurrency
  \item Folly
  \item HPX
  \item Kokkos
  \item Seastar
 \end{itemize}
\end{frame}

\begin{frame}[t]{Давайте напишем прогу, которая...}
 \begin{itemize}
  \item Рисует карту на базе web-тайлов
  \item Рисует много маркеров POI разных приоритетов
  \item Не использует mutex...
  \item Не зависает и не падает на выходе
  \item Лежит на github: \\ \footnotesize{\url{https://github.com/VestniK/mapex}}
 \end{itemize}
\end{frame}

\begin{frame}[t]{План работ}
\begin{onlyenv}<1>
\begin{itemize}
 \item В начале у нас есть синхронный прототип рисующий тайлы лежащие локально на диске.
 \item Распаковка изображений происходит синхронно прямо в UI потоке.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{itemize}
 \item Унесём распаковку в отдельные потоки.
 \item Добавим загрузку изображений по сети.
 \item Реализуем загрузку и кэширование POI.
 \item Распараллелим генерализацию POI разных приоритетов.
\end{itemize}
\end{onlyenv}
\end{frame}

\begin{frame}[t]{На всякий случай}

В угоду лаконичности и удобству чтения слайдов код примеров в презентации упрощён, не следует правилам хорошего тона и
может даже не компилироваться.
\end{frame}

\begin{frame}[fragile,t]{\texttt{future} в UI потоке}
\begin{onlyenv}<1>
\begin{itemize}
 \item Всё взаимодействие с интерфейсом должно происходить в одном потоке.
 \item Обработка пользовательких действий происходит в нём же.
 \item Его нельзя блокировать на долго.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
Есть задачи по загрузке тайлов и загруженные тайлы.
\begin{lstlisting}[style=cppcode]
struct tile_id {
  int tx;
  int ty;
  int z_level;
};

map<tile_id, future<QImage>> tasks;
map<tile_id, QImage> tiles;
 \end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
Перед отрисовкой хотим забирать готовые тайлы без SMS и блокировок.
 \begin{lstlisting}[style=cppcode,belowskip=0pt]
map<tile_id, future<QImage>> tasks;
map<tile_id, QImage> tiles;

for (auto [id, task]: tasks) {
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  if (task.is_ready())
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
    tiles[id] = task.get();
}
 \end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<4>
Или в \texttt{std::future} исполнении
 \begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},belowskip=0pt]
map<tile_id, std::future<QImage>> tasks;
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
map<tile_id, QImage> tiles;

for (auto [id, task]: tasks) {
  if (
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
    task.wait_for(0ms) == std::future_status::ready)
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
    tiles[id] = task.get();
}
 \end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Распаковываем тайлы \texttt{async}'ронно}
\begin{onlyenv}<1>
\begin{itemize}
 \item Самый простой способ создать асинхронную задачу \texttt{async}.
 \item Принимает функцию и аргументы.
 \item Возвращает \texttt{future} на результат.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
Асинхронная загрузка в исполнении \texttt{std::async}
\begin{lstlisting}[style=cppcode]
QImage load_tile(tile_id id);
map<tile_id, std::future<QImage>> tasks;

tasks[id] = std::async(
  launch::async,
  [id] {return load_tile(id);}
);
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
Проблемы:
\begin{itemize}
 \item Удаление задач только через ожидание их завершения
 \item На выходе ждём завершения всех текущих задач
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<4>
Перейдём на \texttt{pc::async}
\begin{lstlisting}[style=cppcode]
QImage load_tile(tile_id id);
map<tile_id, future<QImage>> tasks;

tasks[id] = async(
  QThreadPool::globalInstance(),
  [id] {return load_tile(id);}
);
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Executors}
\begin{onlyenv}<1>
Откуда \texttt{pc::async} знает про \texttt{QThreadPool}?
\begin{itemize}
 \item portable\_concurrency не зависит от Qt
 \item не предоставляет своих рекомендуемых к использованию executor'ов
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
namespace portable_concurrency {
template <>
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
struct is_executor<QThreadPool*>: std::true_type {};
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
} // namespace portable_concurrency

// ADL
template<typename F>
// requires Callable<F, void()> && MoveConstructable<F>
void post(
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  QThreadPool* pool,
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
  F&& task
);
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
namespace portable_concurrency {
template <>
struct is_executor<QThreadPool*>: std::true_type {};
} // namespace portable_concurrency

// ADL
void post(
  QThreadPool* pool,
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  unique_function<void()> task
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
);
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<4>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
namespace portable_concurrency {
template <>
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
struct is_executor<QObject*>: std::true_type {};
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
} // namespace portable_concurrency

// ADL
void post(
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  QObject* pool,
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
  unique_function<void()> task
);
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<5>
Требования на Executor:
\begin{itemize}
 \item Дешёвый для копирования.
 \item Хранение его копии в задаче отсылаемой через \texttt{post} не приводит к циклическим ссылкам и утечкам.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<6>
\textit{\footnotesize{Разобравшись в нюансах мы можем наказать \texttt{QThreadPool} за длинное имя и в последующих слайдах принебрежительно писать \texttt{pool} вместо \texttt{QThreadPool::globalInstance()}}}.
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Сетевые запросы и \texttt{promise}}
\begin{onlyenv}<1>
\begin{itemize}
 \item Мы хотим работать с Qt сетью через \texttt{future}.
 \item Но она асинхронно работает через сигналы.
 \item На помощь приходит \texttt{promise} самый низкоуровневый и сложный в обращении способ взаимодействовать с \texttt{future}.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
class promised_reply: QObject {
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  promise<QNetworkReply*> p_;
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
slots:
  void on_reply_finished() {
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
    p_.set_value(sender());
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
  }
  void on_reply_error() {
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
    p_.set_error(sender()->error());
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
  }
};
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
future<QNetworkReply*> send_request(
  QNetworkAccessManager nm, QUrl url
) {
  promised_reply* listener = new promised_reply;
  QNetworkReply* reply = nm.get(url);
  QMetaObject::connectSlotsByName(this);
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  return listener.p_.get_future();
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
}
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{\texttt{future<future<future<T>{}>{}>}}
\begin{onlyenv}<1>
\begin{itemize}
 \item Вызывать \texttt{send\_request} можно только в сетевом потоке.
 \item Она возвращает \texttt{future}.
 \item Функция \texttt{async} добавляет к козвращаемому значению \texttt{future}.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode]
QNetworkAccessManager nm;

auto f = async(
  &nm, [&nm] {return send_request(nm, url);}
);
\end{lstlisting}
Какой тип вернёт нам \texttt{async}?
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode]
QNetworkAccessManager nm;

future<QNetworkReply*> f = async(
  &nm, [&nm] {return send_request(nm, url);}
);
\end{lstlisting}
Удобный в использовании, а не тот, что в заголовке.
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Цепочки задач}
\begin{onlyenv}<1>
Получение \texttt{QImage} пригодного для отрисовки состоит из двух этапов.
\begin{itemize}
 \item Загрузки по сети.
 \item Распаковки полученного изображения.
\end{itemize}
Второй шаг необходимо уметь запускать по факту завершения первого.
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
map<tile_id, std::future<QImage>> tasks;
QUrl get_tile_url(tile_id);
QImage parse_image(QIODevice&);

tasks[id] = async(&nm, [&nm, id] {
  return send_reques(nm, get_tile_url(id));
});
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
map<tile_id, std::future<QImage>> tasks;
QUrl get_tile_url(tile_id);
QImage parse_image(QIODevice&);

tasks[id] = async(&nm, [&nm, id] {
  return send_reques(nm, get_tile_url(id));
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
}).next(pool, [](QNetworkReply* reply) {
  return parse_image(reply);
});
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<4>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
map<tile_id, std::future<QImage>> tasks;
QUrl get_tile_url(tile_id);
QImage parse_image(QIODevice&);

tasks[id] = async(&nm, [&nm, id] {
  return send_reques(nm, get_tile_url(id));
}).next(pool, [](QNetworkReply* reply) {
  return parse_image(reply);
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
}).then(&widget, [&widget](future<QImage> f) {
  widget.update();
  return f;
});
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Отмена задач {\footnotesize{специфично для portable\_concurrency}}}
\begin{onlyenv}<1>
{\em Q:} Будет ли выполняться \texttt{parse\_image} для уже невидимых тайлов?

{\em A:} Если он ещё не стартовал, а \texttt{future} на его результат уже разрушен, то нет.
\end{onlyenv}
\begin{onlyenv}<2-3>

{\em Q:} А может нужно прервать саму загрузку тайлов?

{\em A:} Обработчик отмены назавершённой задачи можно передать в конструктор \texttt{promise}.\\
\begin{onlyenv}<3>
\footnotesize{Осторожно, поток вызова обработчика неопределён.}
\end{onlyenv}
\end{onlyenv}
\begin{onlyenv}<4>
\begin{lstlisting}[style=cppcode]
QNetworkReply* reply = nm.get(url);
promise<QNetworkReply*> p{
  canceller_arg, [reply] {reply->abort();}
};
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<5>
{\em Q:} А что делать с очень долго выполняющимся синхронным кодом?

{\em A:} Есть ещё одна форма \texttt{then} и \texttt{promise::is\_awaiten}.
\end{onlyenv}
\begin{onlyenv}<6>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
future<T> f;
future<R> res = f.then(
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
  [](promise<R> p, future<T> f) {
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
    not_too_long_op1();
    if (!p.is_awaiten()) return;
    not_too_long_op2();
  }
);
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Загрузка POI}
\begin{onlyenv}<1>
\begin{itemize}
 \item База POI загружается по сети и кэшируется локально.
 \item Включение отображения POI должно происходить быстро.
 \item Одновременно идём в сеть и в кэш и смотрим кто быстрей.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
future<points> load_poi();
points fetch_poi_cache();
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
using poi_future = ???;
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]

poi_future f = when_any(
  load_poi(),
  async(pool, fetch_poi_cache())
);
\end{lstlisting}
\textit{\footnotesize{Тип \texttt{poi\_future} не влез на этот слайд}}
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode]
template<typename Sequence>
struct when_any_result {
  size_t index;
  Sequence futures;
};

using poi_future = future<
  when_any_result<
    tuple<future<points>, future<points>>
  >
>;
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<4>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
future<points> load_poi();
points fetch_poi_cache();
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
using poi_future = when_any_result<
  vector<future<points>>
>;
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]

future<points> futures[2] = {
  load_poi(),
  async(pool, fetch_poi_cache())
};
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt]
auto f = when_any(begin(futures), end(futures));
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Быстрый кэш и отмена запроса}
\begin{onlyenv}<1>
\begin{itemize}
 \item Кэш всегда отвечает первым
 \item \texttt{future} на результат загрузки по сети разрушается
 \item Хочется при этом не отменять загрузку
 \item Для этого есть метод \texttt{future::detach}
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode]
template<typename T>
future<T> future<T>::detach();

future<points> futures[2] = {
  load_poi().detach(),
  async(pool, fetch_poi_cache())
};
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
Отмену можно нарезать фигурно
\begin{lstlisting}[style=cppcode]
auto f = async(pool, foo)
  .next(bar).detach()
  .next(baz);
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Не рисуем пустой кэш}
\begin{onlyenv}<1>
\begin{itemize}
 \item Когда кэш пуст отдавать его содержимое на отрисовку бессмысленно.
 \item В этом случае хочется продолжить дожидаться ответа от сети.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
future<points> f =
  when_any(begin(futures), end(futures))
  .next([](auto seq) {
    points poi = seq.futures[seq.index].get();
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
    if (poi.empty() && seq.index == 1)
      return seq[0];
    return make_ready_future(poi);
  });
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{Генерализация POI}
\begin{onlyenv}<1>
\begin{itemize}
 \item Есть два приоритета POI <<рекламные/обычные>>.
 \item Генерализуем разные приоритеты независимо.
 \item А затем объединяем результат.
\end{itemize}
\end{onlyenv}
\begin{onlyenv}<2>
\begin{lstlisting}[style=cppcode]
using points = vector<geo_point>;
points generalize(points, int z_level);

points ads;
points poi;
auto f_ads = async(pool,
  [=] {return generalize(ads, z_level);});
auto f_poi = async(pool,
  [=] {return generalize(poi, z_level);});
\end{lstlisting}
\end{onlyenv}
\begin{onlyenv}<3>
\begin{lstlisting}[style=cppcode,belowskip=0pt]
auto f = when_all(f_ads, f_poi)
  .next([](
\end{lstlisting}
\begin{lstlisting}[style=cppcode,backgroundcolor=\color{gray!30},aboveskip=0pt,belowskip=0pt]
    tuple<future<points>, future<points>> ready
\end{lstlisting}
\begin{lstlisting}[style=cppcode,aboveskip=0pt,belowskip=0pt]
  ) {
    points g_ads = get<0>(ready).get();
    points g_poi = get<1>(ready).get();
    // ...
  });
\end{lstlisting}
\end{onlyenv}
\end{frame}

\begin{frame}[fragile,t]{В итоге мы имеем}
\begin{itemize}[<+->]
 \item Начав с синхронного прототипа мы легко сделали код асинхронным.
 \item Код управления потоками отделён от описания асинхронных задач.
 \item Порядок исполнения строго определён зависимостью задач друг от друга.
 \item Механизм описания зависимостей не позволяет создавать циклов.
\end{itemize}
\end{frame}

\begin{frame}[t]{Спасибо за внимание}
Мои контакты:

{\footnotesize{\url{sir.vestnik@gmail.com}}\\
\footnotesize{\url{https://github.com/VestniK}}}

Ссылки:

\begin{columns}
\begin{column}{0.5\textwidth}

{\footnotesize{Демо проект:}}\\
\includegraphics[width=0.5\textwidth]{demo-qr.eps}
\end{column}
\begin{column}{0.5\textwidth}

{\footnotesize{portable\_concurrency:}}\\
\includegraphics[height=0.5\textwidth]{pc-qr.eps}
\end{column}
\end{columns}
\end{frame}

\end{document}
